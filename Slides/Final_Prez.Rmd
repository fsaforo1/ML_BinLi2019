---
title: "Predicting Hit Songs - Hot 100 Billboard Chart"
author:
- Frank K. Saforo
- Chris J. Ezelle
date: February 22, 2019
output:
  slidy_presentation:
    #incremental: true
    footer: "F. K. Saforo, C. J. Ezelle, 2/25/2019"
---  

<style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
  .col3 {
    columns: 3 100px;
    -webkit-columns: 3 100px;
    -moz-columns: 3 100px;
  }
</style>      

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(easypackages)
libraries('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'reshape','caret', 'tidyverse',
          'MASS', 'DT', 'psych', 'ggplot2', 'e1071', 'pdp', 'xgboost', 'htmlwidgets', 'pryr', 'vip',
          'dplyr', 'Amelia', 'mice', 'tidyverse', 'RColorBrewer', 'rpart', 'caTools', 'treemap', 'earth',
          'AppliedPredictiveModeling', 'rpart.plot', 'randomForest', 'pROC', 'xgboost', 'broom',
          'Matrix', 'vcd', 'RANN', 'plyr', 'plotly', 'kableExtra', 'gbm', 'PRROC', 'Ckmeans.1d.dp')
```

## Overview


- Introduction  


- The Data and EDA  


- Model Building and Evaluation    


- Results and Interpretation    


- Recommendation and Conclusion



## Introduction

- Data was extracted from the Spotify API 
- Get out of bed



## Collecting the Data
<center>
```{r, out.width = "60%", echo=FALSE}
knitr::include_graphics("./Slides/prz_000.png")
```
</center>   

 - **Latest data retrieval was on December 28, 2018**


## Data Snap  

```{r, echo=FALSE, warning=FALSE, message=FALSE}
str(newdata)
object_size(newdata)
```




## The Data...   

  - Tempo: Beats Per Minute (BPM) of the song.    
  - Energy: The energy of a song, the higher the value, the more energetic.     
  - Danceability: The higher the value, the easier it is to dance to this song.     
  - Loudness: The higher the value, the louder the song (in dB).    
  - Valence: The higher the value, the more positive mood for the song.     
  - Length: The duration of the song.    
  - Acousticness: The higher the value the more acoustic the song is.      
  - Release Year: The year each song was released.     
  - **Popularity (Target Variable)**: The higher the value (on a scale of 0 to 100) the more popular the song is.

**Source:** See features description [here](http://static.echonest.com/SortYourMusic/)

## Which Variables provide the most variation?   

<div class="col2">
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
plotFilterValues(var_imp,feat.type.cols = TRUE)
corrplot(M, type = "upper")
```
</div>  

## How are the 'Top' features related to Popularity

<div class="col2">
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
ggpairs(newdata[sample(1:dim(newdata)[1], 1000), 
                c("loudness","instrumentalness","duration_ms","danceability","popularity")])

a
```
</div>

## Most Popular Songs of 2018

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
top5plot
```


## Top 100 Songs by Key and Emotion   

<div class="col2">  
```{r, echo=FALSE, warning=FALSE, message=FALSE, out.width = "80%", fig.align='center'}
treemap(ctone2, index="keys", vSize="count", type="index", 
        palette="Pastel2", title="Top 100 Songs Key charactersics", fontsize.title=12)

treemap(tone2, index="keylabel", vSize="count", type="index", 
        palette="Pastel2", title="Top 100 Songs Key charactersics and Emotion", fontsize.title=11)
```
</div>


## How does mood affect the popularity of a song?
```{r, echo=FALSE, warning=FALSE, message=FALSE, out.width = "80%", fig.align='center'}
knitr::include_graphics("./Slides/prz_mood.png")
```


## Energy Vs. Popularity
```{r, echo=FALSE, warning=FALSE, message=FALSE, out.width = "80%", fig.align='center'}
knitr::include_graphics("./Slides/prz_energy.png")
```

## Does the name of the song matter?

```{r, echo=FALSE, warning=FALSE, message=FALSE, out.width = "120%", fig.align='center'}
library(wordcloud)
wordcloud(newdata$track_name, max.words=100 ,
          random.order=FALSE,rot.per=0.35,colors=brewer.pal(4, "Dark2"), main="Title")
```


## Model Building and Evaluation

<center>
```{r, echo=FALSE, warning=FALSE, message=FALSE, out.width = "80%", fig.align='center'}
knitr::include_graphics("./Slides/prz_mod.png")
```
</center>

## The Regression Problem 

Popularity is a copntinuous variable that ranges between 0 and 1 
```{r, echo=FALSE}
print(paste("Minimum Popularity is", 0.1))
print(paste("Maximum Popularity is", 0.9))
```

Models considered:    
    - Model appropriate for the random component of the response variable; a **GLM with beta random component**.      
    - A  model that relaxes assumptions of linearity and probability distribution; a nonparametric model **Multivariate Adaptive Regression Splines**
    
### The Beta Distribution
Ferrari and Cribari-Neto, 2004 proposed a reparametrization of the **Beta Distribution** , $\mu=p/(p+q)$ and $\phi=p+q$, with the density function being:
$$f(y \mid \mu,\phi)=\frac{\Gamma(\phi)}{\Gamma(\mu\phi)\Gamma((1-\mu)\phi)}y^{\mu\phi-1}(1-y)^{(1-\mu)\phi-1}, \;\;\; \;\;0<y<1$$

$$E(y)=\mu$$
and
$$Var(y)=\frac{\mu(1-\mu)}{1+\phi}$$
The parameter $\phi$ is known as the precision parameter. Notice that for fixed $\mu$, $\phi$ gets larger and variance of $y$ gets smaller.
The inverse of $\phi^{-1}$ is also known as the dispersion parameter.   

This parameterization is particularly useful in linear regression since it involves modeling the mean or the expected value of the response variable$(y)$. Thus $\mu$ is the mean of the response variable.  
  
## The Beta [GLM] Model  

Following the latter parameterization of the beta distribution proposed by Ferrari and Cribari-Neto(2004) above, let $y_1, y_2, ...,y_n$ be a random sample such that $y_i \sim Beta(\mu_i,\phi)\;\;\;\;i=1,2,...,n$. Then the beta regression model is defined as:   

$$g(\mu_i)=x_i^T\beta$$  
where $\beta=(\beta_1, \beta_2,...,\beta_p)$ is a $p\times1$ vector of unknown parameters$(p<n), \;\;x_i=(x_{i1},(x_{i},...,(x_{ip})^T$ is the vector of $p$ regressors or the independent variables of this model. $x_i^T\beta=\eta_i$ is the linear predictor or the systematic component of the model.   

Also note that the link function represented by $g(*):(0,1) \implies \mathbb{R}$ is strictly increasing in $*$ and twice differentiable hence continuous everywhere.   

Due the the link, random (beta distribution) and systematic component (linear predictor), the beta regression model can be modelled seen as a Generalized Linear Model (GLM) (Agresti et al. Categroical Data Analysis). This offers flexibility in the choice of the link function to suit particular cases.  Some common link functions are:


### Some Common Link functions

 - **logit** $g(\mu) = log(\frac{\mu}{1-\mu})$, thus $\mu=\frac{e^{x_i^T\beta}}{1+e^{x_i^T\beta}}$
 - **log-log** $g(\mu) = log(-log(\mu))$
 - **Probit** $g(\mu) = \phi^{-1}(\mu)$
 - **Complimentary log-log** $g(\mu) = log(-log(1-\mu))$
 - **Cauchit** $g(\mu) = tan(\pi (\mu - 0.5))$   
 - **Identity** $g(\mu) = \mu$

Like with most GLM, the inverse function $\mu=g^{-1}(x_i^T\beta)$, is a function (linear combination) of the regression parameters $\beta$, hence the maximum likelihood estimation is adopted.



## The Classification Problem
This problem is a classic case of class imbalance with the class of interest being roughly 10 percent of available data.  

```{r, echo=FALSE, warning=FALSE, message=FALSE}
prop.table(table(modData$target))
```

A rather simple criteria was adopted. Fit models that:  

  1. produces the best prediction of classes, and with a variable selection feature   
  
  2. produces the best prediction, and with the best variable explanation
  
Models that meet criteria 1: Models that employ Gradient Boosting Algorithms OR Bagging Algorithms.
  Due to serious computational constraints only the **XGBoost, C5.0** models were considered with optimal parameter turning.   
  
Models that meet criteria 2:   Models that employ Stacking or Bagging algorithms. Here, only the **logistic regression and random forest models** were considered.


## Model Building - Beta Regression Model 

  - First conduct feature selection using the Recursive Feature Elimination (RFE) algorithm        
  
  - Cross-validate model accross a combination of its tuning parameters using selected variables from the RFE: **the link function**, **parameter estimation criteria**, and the **precision parameter**


### Recursive Feature Elimination 

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
dfl <- RFE$results[, -c(3,6)]

dfl[3, 1:2] <- cell_spec(dfl[3, 1:2], "html", color = "white", background = "#D7264E", bold = T)


dfl%>%
  kable(digits=8, row.names = FALSE, escape = FALSE, format = "html") %>%
  kable_styling(bootstrap_options=c("bordered", "responsive","striped"), full_width = FALSE)

df2 <- varImp(RFE)
df2[1:5, 1] <- cell_spec(df2[1:5, 1], "html", color = "white", background = "#D7264E", bold = T)

df2%>%
  kable(digits=8, row.names = TRUE, escape = FALSE, format = "html") %>%
  kable_styling(bootstrap_options=c("bordered", "responsive","striped"), full_width = FALSE)

```

## The Beta Model   

**Tuning Parameters of Beta Model**
```{r, warning=FALSE, message=FALSE}
betamod
```

### Final model and Test Error

```{r, warning=FALSE, message=FALSE}
betamod$finalModel
#varImp(betamod)
RMSE(TEST$popularity, predict(betamod, newdata = TEST))
```


## MARS Model  

  - a piecewise linear model that captures the nonlinearity aspect of polynomial regression by assessing cutpoints (knots) similar to step functions.    
  - Cross-validate to tune model complexity by pruning for an optimal combination of model hyperparameters    
  - **Pruning Parameters**: **degree of interactions** and the **number of retained terms**

### 10-Fold Cross Validation 

```{r, warning=FALSE, message=FALSE, fig.align='center'}
MARS_model$finalModel

# best model
MARS_model$bestTune


# plot results
ggplot(MARS_model)
```

## MARS Model Analysis

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
# Coefficients of the model
coef(MARS_model$finalModel) %>%
  kable(digits=8, row.names = TRUE, escape = FALSE, format = "html") %>%
  kable_styling(bootstrap_options=c("bordered", "responsive","striped"), full_width = FALSE)


# variable importance plots

k1 <- vip(MARS_model, num_features = 40, bar = FALSE, value = "gcv") + ggtitle("GCV")
k2 <- vip(MARS_model, num_features = 40, bar = FALSE, value = "rss") + ggtitle("RSS")

gridExtra::grid.arrange(k1, k2, ncol = 2)
```

### Test Set Diagnostics
```{r, warning=FALSE, message=FALSE}
RMSE(TEST$popularity, predict(MARS_model, newdata = TEST))
```

## The Imbalanced Classification Challenge 

Four sampling schemes were adopted - Weighted, Under, Over and SMOTE (Synthetic Minority Over-sampling Technique).      

Gradient Boosting Machines were tuned to all four schemes.


Below is the outline of the simple strategy:   

  1. Build a base classifier (XGBoost) without any resampling technique;  
  
  2. Build 4 other classifiers (XGBoost) with the same    
  

### Tuning the Extreme Gradient Machine  

```{r, warning=FALSE, message=FALSE}
gg1 <- tuneplot(xgb_tune) + ggtitle('1. Number of Iterations and Learning Rate')+ 
  scale_fill_continuous(guide = guide_legend()) +
    theme(legend.position="bottom")

gg2 <- tuneplot(xgb_tune2) + ggtitle('2. Maximum Depth and Minimum Child Weight')+ 
  scale_fill_continuous(guide = guide_legend()) +
    theme(legend.position="bottom")
gg3 <- tuneplot(xgb_tune3) + ggtitle('3. Column and Row Sampling')+ 
  scale_fill_continuous(guide = guide_legend()) +
    theme(legend.position="bottom")
gg4 <- tuneplot(xgb_tune4) + ggtitle('4. Tuning Gamma')+ 
  scale_fill_continuous(guide = guide_legend()) +
    theme(legend.position="bottom")
gg5 <- tuneplot(xgb_tune5) + ggtitle('5. Reducing the Learning Rate')

grid.arrange(gg1, gg2, ncol=2)
grid.arrange(gg3, gg4, ncol=2)
gg5
```


## Final Models


### The XGBoost Models 

```{r}
xgb_smote.model
xgb_final$bestTune
varImp(xgb_final)
```

### The Random Forest Models
```{r}
models_roc %>% map(auc)
```

### The XGBoost Models 

```{r}
XGB_list_roc %>%map(auc)
xgb_smote.model$evaluation_log
xgb_finalOther$bestTune
varImp(xgb_finalOther)
```


## Conclusion 

